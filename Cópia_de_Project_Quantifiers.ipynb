{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mIPlug/Quantifiers/blob/master/C%C3%B3pia_de_Project_Quantifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52f9630a",
      "metadata": {
        "id": "52f9630a"
      },
      "source": [
        "# QUANTIFICATION EXPERIMENTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6747076",
      "metadata": {
        "id": "f6747076"
      },
      "source": [
        "## IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5cd5fe",
      "metadata": {
        "id": "2c5cd5fe",
        "outputId": "0cdb583c-1ffb-4203-9346-ccab97ab1a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4c45e961319b>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mquantifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifyCountCorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdjustedClassifyCount\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdjustedClassifyCount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mquantifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifyCountCorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifyCount\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifyCount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mquantifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifyCountCorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'quantifiers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from quantifiers.ClassifyCountCorrect.AdjustedClassifyCount import AdjustedClassifyCount\n",
        "from quantifiers.ClassifyCountCorrect.ClassifyCount import ClassifyCount\n",
        "from quantifiers.ClassifyCountCorrect.MAX import MAX\n",
        "from quantifiers.ClassifyCountCorrect.MedianSweep import MedianSweep\n",
        "from quantifiers.ClassifyCountCorrect.ProbabilisticAdjustedClassifyCount import ProbabilisticAdjustedClassifyCount\n",
        "from quantifiers.ClassifyCountCorrect.ProbabilisticClassifyCount import ProbabilisticClassifyCount\n",
        "from quantifiers.ClassifyCountCorrect.T50 import T50\n",
        "from quantifiers.ClassifyCountCorrect.X import Xqtf\n",
        "from quantifiers.DistributionMatching.DyS import DyS\n",
        "from quantifiers.DistributionMatching.HDy import HDy\n",
        "from quantifiers.DistributionMatching.SORD import SORD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YfG6S52GP3ko"
      },
      "id": "YfG6S52GP3ko",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8fa872c5",
      "metadata": {
        "id": "8fa872c5"
      },
      "source": [
        "## Class that holds an experiment. Each experiment contains:\n",
        "#### - training-test     -      An array with the training and the test\n",
        "#### - batch_sizes      -      The sizes of the each test\n",
        "#### - alphas         -           Number of how many positive class distributions that the experiment will have\n",
        "#### - niterations      -       The number of iterations\n",
        "#### - clf             -              A classifier, without fitted to a training set\n",
        "#### - thr            -              The threshold to the classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b68fa5",
      "metadata": {
        "id": "e1b68fa5"
      },
      "outputs": [],
      "source": [
        "class Experiments:\n",
        "    def __init__(self, train_test, niterations, batch_sizes, alphas, clf, thr, path=\"\"):\n",
        "        self.train_test = train_test\n",
        "        self.niterations = niterations\n",
        "        self.batch_sizes = batch_sizes\n",
        "        self.alphas = alphas\n",
        "        self.clf = clf\n",
        "        self.thr = thr\n",
        "        # self.quantifiers = [\"CC\", \"ACC\", \"PCC\", \"PACC\", \"X\", \"MAX\", \"T50\", \"MS\", \"HDy\", \"DyS\", \"SORD\"]\n",
        "        self.quantifiers = [\"CC\", \"ACC\", \"PCC\", \"PACC\", \"X\", \"MAX\", \"T50\", \"MS\", \"HDy\", \"DyS\", \"SORD\"]\n",
        "        self.quantifiers_initialized = {}\n",
        "        self.measure = ['topsoe', 'probsymm', 'hellinger']\n",
        "        columns = [\"sample\", \"Test_size\", \"alpha\", \"actual_prop\", \"pred_prop\", \"abs_error\", \"quantifier\"]\n",
        "        self.table = pd.DataFrame(columns=columns)\n",
        "\n",
        "    def apply_quantifier(self, quantifier, clf, thr, measure, train, test):\n",
        "        if quantifier not in self.quantifiers_initialized:\n",
        "            if quantifier == \"CC\":\n",
        "                cc = ClassifyCount(classifier=clf, threshold=thr)\n",
        "                cc.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"CC\"] = cc\n",
        "\n",
        "                return cc.predict(test)\n",
        "            if quantifier == \"ACC\":\n",
        "                acc = AdjustedClassifyCount(classifier=clf, threshold=thr)\n",
        "                acc.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"ACC\"] = acc\n",
        "\n",
        "                return acc.predict(test)\n",
        "            if quantifier == \"PCC\":\n",
        "                pcc = ProbabilisticClassifyCount(classifier=clf)\n",
        "                pcc.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"PCC\"] = pcc\n",
        "\n",
        "                return pcc.predict(test)\n",
        "\n",
        "            if quantifier == \"PACC\":\n",
        "                pacc = ProbabilisticAdjustedClassifyCount(classifier=clf, threshold=thr)\n",
        "                pacc.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"PACC\"] = pacc\n",
        "\n",
        "                return pacc.predict(test)\n",
        "\n",
        "            if quantifier == \"X\":\n",
        "                x_qtf = Xqtf(classifier=clf)\n",
        "                x_qtf.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"X\"] = x_qtf\n",
        "\n",
        "                return x_qtf.predict(test)\n",
        "\n",
        "            if quantifier == \"MAX\":\n",
        "                max_qtf = MAX(classifier=clf)\n",
        "                max_qtf.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"MAX\"] = max_qtf\n",
        "\n",
        "                return max_qtf.predict(test)\n",
        "\n",
        "            if quantifier == \"T50\":\n",
        "                t50 = T50(classifier=clf)\n",
        "                t50.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"T50\"] = t50\n",
        "\n",
        "                return t50.predict(test)\n",
        "\n",
        "            if quantifier == \"MS\":\n",
        "                ms = MedianSweep(classifier=clf)\n",
        "                ms.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"MS\"] = ms\n",
        "\n",
        "                return ms.predict(test)\n",
        "\n",
        "            if quantifier == \"HDy\":\n",
        "                hdy = HDy(classifier=clf)\n",
        "                hdy.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"HDy\"] = hdy\n",
        "\n",
        "                return hdy.predict(test)\n",
        "\n",
        "            if quantifier == \"DyS\":\n",
        "                dys = DyS(classifier=clf, similarity_measure=measure)\n",
        "                dys.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"DyS\"] = dys\n",
        "\n",
        "                return dys.predict(test)\n",
        "\n",
        "            if quantifier == \"SORD\":\n",
        "                sord = SORD(classifier=clf)\n",
        "                sord.fit(train[0], train[1])\n",
        "                self.quantifiers_initialized[\"SORD\"] = sord\n",
        "\n",
        "                return sord.predict(test)\n",
        "        else:\n",
        "            return self.quantifiers_initialized[quantifier].predict(test)\n",
        "\n",
        "    def make_experiment(self):\n",
        "        if type(self.alphas) is list:\n",
        "            alpha_values = round(self.alphas, 2)  # Class Proportion\n",
        "        else:\n",
        "            alpha_values = [round(x, 2) for x in np.linspace(0, 1, self.alphas)]  # Class Proportion\n",
        "\n",
        "        test = pd.concat([self.train_test[1], self.train_test[3]], axis='columns')\n",
        "\n",
        "        test_pos = test.loc[test['class'] == 1]  # seperating positive test examples\n",
        "        test_neg = test.loc[test['class'] == 0]  # seperating negative test examples\n",
        "\n",
        "        for sample_size in self.batch_sizes:  # Varying test set sizes\n",
        "            for alpha in alpha_values:  # Varying positive class distribution\n",
        "                for iteration in range(self.niterations):\n",
        "                    pos_class_size = int(round(sample_size * alpha, 2))\n",
        "                    neg_class_size = sample_size - pos_class_size\n",
        "\n",
        "                    if pos_class_size is not sample_size:\n",
        "                        positive_samples = test_pos.sample(int(pos_class_size), replace=False)\n",
        "                    else:\n",
        "                        positive_samples = test_neg.sample(frac=1, replace=False)\n",
        "\n",
        "                    negative_samples = test_neg.sample(int(neg_class_size), replace=False)\n",
        "\n",
        "                    test_sample = pd.concat([positive_samples, negative_samples])\n",
        "                    testY = test_sample[\"class\"]\n",
        "                    testX = test_sample.drop(['class'], axis='columns')\n",
        "\n",
        "                    # Counting num of actual positives in test sample\n",
        "                    n_pos_test_sample = list(testY).count(1)\n",
        "\n",
        "                    # actual pos class prevalence in generated sample\n",
        "                    calc_prop_pos_class = round(n_pos_test_sample / len(test_sample), 2)\n",
        "\n",
        "                    for iquantifier in self.quantifiers:\n",
        "                        # .............Calling of Methods.................\n",
        "                        pred_pos_prop = self.apply_quantifier(quantifier=iquantifier, clf=self.clf,\n",
        "                                                              thr=self.thr,\n",
        "                                                              measure=self.measure[iteration],\n",
        "                                                              train=[self.train_test[0], self.train_test[2]],\n",
        "                                                              test=testX)\n",
        "                        pred_pos_prop = round(pred_pos_prop[1], 2)  # Getting only the positive proportion\n",
        "\n",
        "                        # absolute error\n",
        "                        abs_error = round(abs(calc_prop_pos_class - pred_pos_prop), 2)\n",
        "                        result = {'sample': iteration + 1, 'Test_size': sample_size, 'alpha': alpha,\n",
        "                                  'actual_prop': calc_prop_pos_class, 'pred_prop': pred_pos_prop,\n",
        "                                  'abs_error': abs_error, 'quantifier': iquantifier}\n",
        "                        result = pd.DataFrame([result])\n",
        "\n",
        "                        self.table = pd.concat([self.table, result], ignore_index=True)\n",
        "\n",
        "    # The datasets needs to be with the labels in the first column\n",
        "    def create_files(datasets:list, path, clf):\n",
        "        exists = os.path.existis(path)\n",
        "        if path.contains(\"csv\"):\n",
        "          if path is f\"{path}\\\\experiment{i + 1}.csv\":\n",
        "            if exists:\n",
        "              path = f\"{path[:-5]}exp{i+1}.csv\"\n",
        "            else:\n",
        "              path = f\"{path[:-5]}{i+1}.csv\"\n",
        "          else:\n",
        "            path = f\"{path[:-5]}{i+1}.csv\"\n",
        "        else:\n",
        "          if exists:\n",
        "            path = f\"{path}\\\\exp{i+1}.csv\"\n",
        "          else:\n",
        "            path = f\"{path}\\\\experiment{i + 1}.csv\"\n",
        "        for i, data in enumerate(datasets):\n",
        "          X = data.iloc[:, 1:]\n",
        "          y = data.iloc[:, 0]\n",
        "          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "          train_test = [X_train, X_test, y_train, y_test]\n",
        "\n",
        "          #                        train_test, niterations, batch_sizes, alphas, clf, thr\n",
        "          experiment = Experiments(train_test, 3, range(10, 101, 10), [0.0, 0.2, 0.5, 0.8, 1.0], clf, 0.5)\n",
        "          experiment.make_experiment()\n",
        "\n",
        "          experiment.return_table().to_csv(path, index=False)\n",
        "\n",
        "    def return_table(self):\n",
        "        return self.table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3524d68b",
      "metadata": {
        "id": "3524d68b"
      },
      "source": [
        "## Importing data, and mapping the target class to 1's and 0's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e44272",
      "metadata": {
        "scrolled": false,
        "id": "56e44272"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    data1 = pd.read_csv(\n",
        "        \"C:\\\\Users\\Luiz Fernando\\\\JupyterFiles\\\\Quantifier-project\\\\Quantifiers\\\\data\\\\AedesSex.csv\")\n",
        "    data1['class'] = data1['class'].map(lambda x: 0 if x == 2 else 1)\n",
        "\n",
        "    data2 = pd.read_csv(\n",
        "        \"C:\\\\Users\\Luiz Fernando\\\\JupyterFiles\\\\Quantifier-project\\\\Quantifiers\\\\data\\\\BNG.csv\")\n",
        "    data2['class'] = data2['class'].map(lambda x: 0 if x == 2 else 1)\n",
        "\n",
        "    data3 = pd.read_csv(\n",
        "        \"C:\\\\Users\\Luiz Fernando\\\\JupyterFiles\\\\Quantifier-project\\\\Quantifiers\\\\data\\\\click-prediction.csv\")\n",
        "    data3['class'] = data3['class'].map(lambda x: 0 if x == 2 else 1)\n",
        "\n",
        "    datas = [data1, data2, data3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f12d5733",
      "metadata": {
        "id": "f12d5733"
      },
      "source": [
        "## Making the experiments of each one of the three datas, containing :\n",
        "#### 3 iterations;\n",
        "#### 10 different sizes of tests;\n",
        "#### 11 diferrents distributions of positive class;\n",
        "#### classifier Random Forest\n",
        "#### 0.5 of threshold\n",
        "## All the results of the experiments will be in external files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a10518f",
      "metadata": {
        "scrolled": true,
        "id": "0a10518f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}